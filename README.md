# GPT Model For Summarizing Articles/News 
###### (Generative pre-trained model)
# [TAJREED]
* GPT built from scratch
* Utilizing a pre-trained model
-----------------------------------------------------------------------------------------------------------------------------------------------------
## ABOUT THE PROJECT
In situations where time is limited
TAJREED offers the solution for a quick
summarization of Arabic articles allowing users to
capture the key points with just a click.
-----------------------------------------------------------------------------------------------------------------------------------------------------
## GPT BUILT FROM SCRATCH
#### Steps followed to build the transformer model:
1. Embeddings (Word to vectors)
2. Defined the basic building blocks: Multi-Head Attention, Position-wise Feed-
Forward Networks, Positional Encoding
3. Built the Encoder and Decoder layers
4. Combined Encoder and Decoder layers
5. Trained the model

-----------------------------------------------------------------------------------------------------------------------------------------------------
## PRE-TRAINED MODEL
#### The pre-trained model
* Was trained on the CrossSum dataset
containing 1.68 million article-
summary pairs
* The dataset had 1,500+ different
Languages
* CrossSum is considered the largest
non-English-focused dataset
